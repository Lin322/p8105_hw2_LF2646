P8105\_HW02\_LF2649
================
Lin\_Feng\_LF2649
September 24, 2020

-   [Problem 1](#problem-1)
    -   [Read the Mr.Traswheel dataset](#read-the-mr.traswheel-dataset)
    -   [Read precipatation data for 2018 and 2017](#read-precipatation-data-for-2018-and-2017)
    -   [Combine annual precipitation:](#combine-annual-precipitation)
-   [Problem 2](#problem-2)
    -   [Import, clean, and tidy the NYC Transit data. Convert "entry".](#import-clean-and-tidy-the-nyc-transit-data.-convert-entry.)
    -   [Description of the dataset](#description-of-the-dataset)
    -   [Distinct statione, ADA, and vending](#distinct-statione-ada-and-vending)
-   [Problem 3](#problem-3)
    -   [First, deal with pols-month.csv](#first-deal-with-pols-month.csv)
    -   [Second, deal with snp.csv](#second-deal-with-snp.csv)
    -   [Third, deal with the unemployment dataset](#third-deal-with-the-unemployment-dataset)
    -   [Join the datasets](#join-the-datasets)

``` r
library(tidyverse)
```

    ## -- Attaching packages -------------------------------------------------------------------------------- tidyverse 1.3.0 --

    ## v ggplot2 3.3.2     v purrr   0.3.4
    ## v tibble  3.0.3     v dplyr   1.0.2
    ## v tidyr   1.1.2     v stringr 1.4.0
    ## v readr   1.3.1     v forcats 0.5.0

    ## -- Conflicts ----------------------------------------------------------------------------------- tidyverse_conflicts() --
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

Problem 1
=========

Read the Mr.Traswheel dataset
-----------------------------

``` r
trashwheel_df = read_xlsx(
    "./Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
    sheet = "Mr. Trash Wheel", 
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls), 
    sports_balls = as.integer(sports_balls)
  )
```

Read precipatation data for 2018 and 2017
-----------------------------------------

``` r
precip_2018=
  read_excel(
    "./Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation", 
    skip = 1 
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)



precip_2017=
  read_excel(
    "./Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation", 
    skip = 1) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Combine annual precipitation:
-----------------------------

``` r
month_df = tibble(
    month = 1:12, 
    month_name = month.name
)

precip_df = bind_rows(precip_2018, precip_2017)

precip_df = left_join(precip_df, month_df, by = "month")
```

The dataset contains information from the Mr. Trashwheel trash collector in Baltimore, Maryland. As trash enters the inner harboe, the trashwheel collects that trash, and stores it in a dumster. The dataset contains information on year, month, and trash collected, include some specific kinds of trash. There are a lot of 344 rows in pur final dataset. Additional datasheets include month and year. In this dataset:

-   The median number of sports balls found in a dumpster in 2017 was 8
-   The total precipitation in 2018 was 70.33 inches.

Problem 2
=========

Import, clean, and tidy the NYC Transit data. Convert "entry".
--------------------------------------------------------------

``` r
 nyc_trans = 
  read_csv("./NYC_Transit.csv", 
           col_types = cols(
             Route8 = col_character(),
             Route9 = col_character(),
             Route10 = col_character(),
             Route11 = col_character()
           )) %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  pivot_longer(
    route1:route11, 
    names_to = "route_name", 
    names_prefix = "route_number", 
    values_to = "exit") %>% 
  
  mutate(entry = recode(entry, YES = "TRUE", NO = "FALSE")) 
```

Description of the dataset
--------------------------

This dataset contains information about each entrance and exit for each subway station in NYC. Data cleaning steps include formatting variable names into proper style, selecting needed variables, tidying the route names and number, and convert the character "entry" into logical variable. After the cleaning an dtidying, there are total 20548 rows and 10 columns in the dataset. It is a tidy dataset with 10 variables: line, station\_name, station\_latitude, station\_longitude, entrance\_type, entry, vending, ada, route\_name, exit.

Distinct statione, ADA, and vending
-----------------------------------

``` r
a = distinct(nyc_trans, line, station_name) %>% 
    count()

b = filter(nyc_trans, ada == TRUE) %>%
    distinct(line, station_name) %>%
    count()

c = filter(nyc_trans, entry == TRUE, vending == "NO") %>%
    distinct(line, station_name) %>%
    count()
```

-   There are 465 stations in NYC
-   84 stations are ADA compliant among all stations in NYC.
-   The propotion of station entrances / exits without vending allow entrance is 0.0924731.

Problem 3
=========

First, deal with pols-month.csv
-------------------------------

-   clean the data in pols-month.csv.
-   Use separate() to break up the variable mon into integer variables year, month, and day;
-   replace month number with month name;
-   create a president variable taking values gop and dem, and remove prez\_dem and prez\_gop;
-   and remove the day variable.

``` r
pols_df = 
  read_csv("./5308/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(mon,into = c("year", "month", "day")) %>% 
  mutate(month = month.abb[as.factor(month)]) %>% 
  mutate(
    president = case_when(
      prez_gop == 1 ~ "gop",
      prez_dem == 1 ~ "dem",
      TRUE ~ "na")) %>% 
  relocate(day,prez_gop,prez_dem) %>% 
  select(year:president)
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

Second, deal with snp.csv
-------------------------

-   clean the data in snp.csv using a similar process to the above.
-   For consistency across datasets, arrange according to year and month,
-   and organize so that year and month are the leading columns.

``` r
snp_df = read_csv("./5308/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(date, sep="/", into = c("month", "day", "year")) %>% 
  mutate(month = month.abb[as.factor(month)]) %>% 
  select(year, month,close)
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

Third, deal with the unemployment dataset
-----------------------------------------

-   tidy the unemployment data so that it can be merged with the previous datasets.
-   This process will involve switching from “wide” to “long” format;
-   ensuring that key variables have the same name;
-   and ensuring that key variables take the same values.

``` r
unemp_df = read_csv("./5308/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(jan:dec, 
    names_to = "month", 
    values_to = "unemployment") %>% 
    mutate(month = month.abb[as.factor(month)]) %>% 
 mutate(year = as.character(year))
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

Join the datasets
-----------------

``` r
join1_df = left_join(pols_df, snp_df, by = c("year","month"))

join_df = left_join(join1_df,unemp_df, by = c("year", "month")) 
```

This dataset is retrieved from FiveThirtyEight website. In the join\_df dataset, we have 822 rows and 11 variables: year, month, gov\_gop, sen\_gop, rep\_gop, gov\_dem, sen\_dem, rep\_dem, president, close, unemployment. This dataset is created from left-joining three subdataset: Standard & Poor’s stock market index (S&P) dataset (snp\_df), unemployment dataset (unemp\_df), and umber of national politicians who are democratic or republican at any given time. The recorded data are from
